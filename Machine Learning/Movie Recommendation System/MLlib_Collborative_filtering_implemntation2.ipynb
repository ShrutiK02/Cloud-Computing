{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVrWIvCVU76N",
        "outputId": "2f216ca8-4323-476a-ee38-ce623c4c01db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=84298e58d8215e62566384715266c5e8318985c0c0c5b9e8819785b6946709cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "# https://grouplens.org/datasets/movielens/100k/\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n"
      ],
      "metadata": {
        "id": "jxPRnP6tX0mg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating"
      ],
      "metadata": {
        "id": "bWbP79zmX0y0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  sc = SparkContext(appName=\"PythonCollaborativeFiltering\")\n",
        "  !wget \"https://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "  !unzip ml-100k.zip\n",
        "  data = sc.textFile(\"ml-100k/u.data\")\n",
        "  #data = sc.textFile(\"https://grouplens.org/datasets/movielens/100k/u.data\")\n",
        "  ratings = data.map(lambda l: l.split('\\t')).map(lambda l: Rating(int(l[0]),int(l[1]), float(l[2])))\n",
        "  rank = 10\n",
        "  numIterations = 10\n",
        "  model = ALS.train(rank=rank, iterations=numIterations, ratings=ratings)\n",
        "  testdata = ratings.map(lambda p: (p[0], p[1]))\n",
        "  predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "  ratesAndPreds = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
        "  MSE = ratesAndPreds.map(lambda r: ((r[1][0] - r[1][1])**2)).mean()\n",
        "  print(\"Mean Squared Error = \" + str(MSE))\n",
        "\n",
        "  model.save(sc, \"target/tmp/myCollaborativeFilter\")\n",
        "  sameModel = MatrixFactorizationModel.load(sc, \"target/tmp/myCollaborativeFilter\")\n",
        "  sc.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AUl14TJX01T",
        "outputId": "5726ce1b-b5f3-4ba0-d65e-eda0050a0333"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-17 02:54:03--  https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  3.45MB/s    in 1.4s    \n",
            "\n",
            "2024-07-17 02:54:06 (3.45 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n",
            "Mean Squared Error = 0.4844291448471857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "v5es6OYGX04x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NCko2_UQcFJp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}