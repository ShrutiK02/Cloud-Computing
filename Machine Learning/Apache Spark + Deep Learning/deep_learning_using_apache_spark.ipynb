{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aJ0JpoxjHR4",
        "outputId": "cde37665-852d-4362-a907-e390cc32b20f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488490 sha256=d1dcf00f332760abc70a9664ca84054cf5ae82113801c271d29f3ac9b03831fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "X_l130E7jXFb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\"\n"
      ],
      "metadata": {
        "id": "HR8nSPRKj8A4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init('/content/spark-3.1.2-bin-hadoop2.7')\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "6pr08aRdmi-C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "curl -O http://download.tensorflow.org/example_images/flower_photos.tgz\n",
        "tar xzf flower_photos.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADJLs1sTm2Dw",
        "outputId": "7143335d-95b1-4de2-ac8e-528b59ad3fb3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  3  218M    3 8216k    0     0  12.3M      0  0:00:17 --:--:--  0:00:17 12.3M\r 44  218M   44 96.0M    0     0  64.7M      0  0:00:03  0:00:01  0:00:02 64.6M\r 84  218M   84  183M    0     0  75.4M      0  0:00:02  0:00:02 --:--:-- 75.4M\r100  218M  100  218M    0     0  79.2M      0  0:00:02  0:00:02 --:--:-- 79.2M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [code]\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyYSV44bnUGW",
        "outputId": "5f7bb62e-5b9e-46a0-dade-e0d9faa3c122"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "directory = 'flower_photos'\n",
        "for filename in os.listdir(directory):\n",
        "    print(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V054dVNwndw3",
        "outputId": "37ba86cc-b5d7-4c50-9920-2df07ae1a555"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tulips\n",
            "dandelion\n",
            "LICENSE.txt\n",
            "daisy\n",
            "roses\n",
            "sunflowers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "img_dir = '/content/flower_photos'\n",
        "os.makedirs(img_dir + \"/tulips\", exist_ok=True)\n",
        "os.makedirs(img_dir + \"/daisy\", exist_ok=True)"
      ],
      "metadata": {
        "id": "DXnnrhOnn3Xi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source_dir = '/content/flower_photos'\n",
        "img_dir = 'content/photos'  # Make sure this is defined correctly\n",
        "\n",
        "def copy_tree(src, dst):\n",
        "    try:\n",
        "        if not os.path.exists(dst):\n",
        "            os.makedirs(dst)\n",
        "        shutil.copytree(src, dst, dirs_exist_ok=True)\n",
        "        print(f\"Successfully copied from {src} to {dst}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error copying from {src} to {dst}: {e}\")\n",
        "\n",
        "copy_tree(os.path.join(source_dir, 'tulips'), os.path.join(img_dir, 'tulips'))\n",
        "copy_tree(os.path.join(source_dir, 'daisy'), os.path.join(img_dir, 'daisy'))\n",
        "\n",
        "try:\n",
        "    shutil.copy(os.path.join(source_dir, 'LICENSE.txt'), img_dir)\n",
        "    print(\"Successfully copied LICENSE.txt\")\n",
        "except Exception as e:\n",
        "    print(f\"Error copying LICENSE.txt: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxIhkOpRoCif",
        "outputId": "d300768c-47f7-4f3b-d8f0-e6ad3adea61e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully copied from /content/flower_photos/tulips to content/photos/tulips\n",
            "Successfully copied from /content/flower_photos/daisy to content/photos/daisy\n",
            "Successfully copied LICENSE.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_dir = '/content/content/photos'  # Ensure this is correctly defined\n",
        "sample_img_dir = os.path.join(img_dir, 'sample')\n",
        "\n",
        "# Create the sample image directory\n",
        "os.makedirs(sample_img_dir, exist_ok=True)\n",
        "\n",
        "# List files in 'tulips' and 'daisy' directories\n",
        "def list_files(directory, num_files):\n",
        "    return sorted([os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))])[:num_files]\n",
        "\n",
        "tulips_files = list_files(os.path.join(img_dir, 'tulips'), 1)\n",
        "daisy_files = list_files(os.path.join(img_dir, 'daisy'), 2)\n",
        "files = tulips_files + daisy_files\n",
        "\n",
        "# Copy selected files to 'sample_img_dir'\n",
        "for file_path in files:\n",
        "    try:\n",
        "        shutil.copy(file_path, sample_img_dir)\n",
        "        print(f\"Copied {file_path} to {sample_img_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error copying {file_path}: {e}\")\n",
        "\n",
        "# List and display contents of the sample image directory\n",
        "sample_img_dir_contents = os.listdir(sample_img_dir)\n",
        "print(\"Contents of sample_img_dir:\")\n",
        "for item in sample_img_dir_contents:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GoAFP_ioc1X",
        "outputId": "d3799775-27d4-4705-b588-44c0891fe2c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied /content/content/photos/tulips/100930342_92e8746431_n.jpg to /content/content/photos/sample\n",
            "Copied /content/content/photos/daisy/100080576_f52e8ee070_n.jpg to /content/content/photos/sample\n",
            "Copied /content/content/photos/daisy/10140303196_b88d3d6cec.jpg to /content/content/photos/sample\n",
            "Contents of sample_img_dir:\n",
            "10140303196_b88d3d6cec.jpg\n",
            "100930342_92e8746431_n.jpg\n",
            "100080576_f52e8ee070_n.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_dir = '/content/content/photos'  # Ensure this is correctly defined\n",
        "sample_img_dir = os.path.join(img_dir, 'sample')\n",
        "\n",
        "# Create the sample image directory\n",
        "os.makedirs(sample_img_dir, exist_ok=True)\n",
        "\n",
        "# List files in 'tulips' and 'daisy' directories\n",
        "def list_files(directory, num_files):\n",
        "    return sorted([os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))])[:num_files]\n",
        "\n",
        "tulips_files = list_files(os.path.join(img_dir, 'tulips'), 1)\n",
        "daisy_files = list_files(os.path.join(img_dir, 'daisy'), 2)\n",
        "files = tulips_files + daisy_files\n",
        "\n",
        "# Copy selected files to 'sample_img_dir'\n",
        "for file_path in files:\n",
        "    try:\n",
        "        shutil.copy(file_path, sample_img_dir)\n",
        "        print(f\"Copied {file_path} to {sample_img_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error copying {file_path}: {e}\")\n",
        "\n",
        "# List and display contents of the sample image directory\n",
        "sample_img_dir_contents = os.listdir(sample_img_dir)\n",
        "print(\"Contents of sample_img_dir:\")\n",
        "for item in sample_img_dir_contents:\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_KVYoCKo235",
        "outputId": "452eccbf-f400-45ef-9a88-0ab303b64145"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied /content/content/photos/tulips/100930342_92e8746431_n.jpg to /content/content/photos/sample\n",
            "Copied /content/content/photos/daisy/100080576_f52e8ee070_n.jpg to /content/content/photos/sample\n",
            "Copied /content/content/photos/daisy/10140303196_b88d3d6cec.jpg to /content/content/photos/sample\n",
            "Contents of sample_img_dir:\n",
            "10140303196_b88d3d6cec.jpg\n",
            "100930342_92e8746431_n.jpg\n",
            "100080576_f52e8ee070_n.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define directories\n",
        "tulips_dir = '/content/content/photos/tulips'\n",
        "daisy_dir = '/content/content/photos/daisy'\n",
        "\n",
        "# Function to load images from a directory and assign labels\n",
        "def load_images_and_labels(directory, label):\n",
        "    image_paths = [os.path.join(directory, fname) for fname in os.listdir(directory) if os.path.isfile(os.path.join(directory, fname))]\n",
        "    images = []\n",
        "    labels = []\n",
        "    for path in image_paths:\n",
        "        img = tf.io.read_file(path)\n",
        "        img = tf.image.decode_image(img, channels=3)\n",
        "        img = tf.image.resize(img, [224, 224])  # Resize to a standard size\n",
        "        img = img / 255.0  # Normalize to [0, 1] range\n",
        "        images.append(img.numpy())\n",
        "        labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "# Load images and labels\n",
        "tulips_images, tulips_labels = load_images_and_labels(tulips_dir, 1)\n",
        "daisy_images, daisy_labels = load_images_and_labels(daisy_dir, 0)\n",
        "\n",
        "# Combine images and labels into a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'image': tulips_images + daisy_images,\n",
        "    'label': tulips_labels + daisy_labels\n",
        "})\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'])\n",
        "\n",
        "# Convert DataFrames to TensorFlow Datasets\n",
        "def df_to_tf_dataset(df, batch_size=32):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((list(df['image']), list(df['label'])))\n",
        "    dataset = dataset.shuffle(buffer_size=len(df))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "train_ds = df_to_tf_dataset(train_df)\n",
        "test_ds = df_to_tf_dataset(test_df)"
      ],
      "metadata": {
        "id": "MKUZfy6ipA-9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Define directories\n",
        "tulips_dir = '/content/content/photos/tulips'\n",
        "daisy_dir = '/content/content/photos/daisy'\n",
        "\n",
        "# Function to load images from a directory and assign labels\n",
        "def load_images_and_labels(directory, label):\n",
        "    image_paths = [os.path.join(directory, fname) for fname in os.listdir(directory) if os.path.isfile(os.path.join(directory, fname))]\n",
        "    images = []\n",
        "    labels = []\n",
        "    for path in image_paths:\n",
        "        img = tf.io.read_file(path)\n",
        "        img = tf.image.decode_image(img, channels=3)\n",
        "        img = tf.image.resize(img, [299, 299])  # Resize to a standard size\n",
        "        img = img / 255.0  # Normalize to [0, 1] range\n",
        "        images.append(img.numpy())\n",
        "        labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "# Extract features from images\n",
        "def extract_features(images):\n",
        "    # Load the InceptionV3 model pre-trained on ImageNet\n",
        "    model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "    # Preprocess images\n",
        "    images = [tf.image.resize(img, [299, 299]) for img in images]\n",
        "    images = np.array([tf.keras.applications.inception_v3.preprocess_input(img) for img in images])\n",
        "\n",
        "    # Extract features\n",
        "    features = model.predict(images)\n",
        "    return features\n",
        "\n",
        "# Load and preprocess data\n",
        "tulips_images, tulips_labels = load_images_and_labels(tulips_dir, 1)\n",
        "daisy_images, daisy_labels = load_images_and_labels(daisy_dir, 0)\n",
        "\n",
        "# Combine images and labels into a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'image': tulips_images + daisy_images,\n",
        "    'label': tulips_labels + daisy_labels\n",
        "})\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'])\n",
        "\n",
        "# Extract features from training and testing data\n",
        "X_train = extract_features(train_df['image'].tolist())\n",
        "y_train = train_df['label'].values\n",
        "X_test = extract_features(test_df['image'].tolist())\n",
        "y_test = test_df['label'].values\n",
        "\n",
        "# Create and train the Logistic Regression model using the 'saga' solver\n",
        "lr = LogisticRegression(max_iter=20, solver='saga', penalty='elasticnet', l1_ratio=0.3, C=1/0.05)\n",
        "\n",
        "# Train the model\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test set accuracy = {accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISqFcr8fpdSj",
        "outputId": "a5b38be7-1e8f-42d6-b55b-957bf08ed5bd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 8s/step\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 8s/step\n",
            "Test set accuracy = 0.819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test set accuracy = {accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_oC5Wq5qFzF",
        "outputId": "2d6adc86-0cbf-413d-fa27-630ce76c2715"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy = 0.819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming df is the DataFrame with 'probability' and 'label' columns\n",
        "# For demonstration purposes, I'll create a sample DataFrame\n",
        "# Replace this with actual DataFrame creation/loading code\n",
        "data = {\n",
        "    'filePath': ['path/to/img1', 'path/to/img2', 'path/to/img3'],\n",
        "    'probability': [np.array([0.1, 0.9]), np.array([0.8, 0.2]), np.array([0.4, 0.6])],\n",
        "    'label': [1, 0, 1]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Extract the probability for the positive class (index 1)\n",
        "df['p_1'] = df['probability'].apply(lambda v: float(v[1]))\n",
        "\n",
        "# Sort DataFrame by the absolute difference between 'p_1' and 'label'\n",
        "df['abs_diff'] = np.abs(df['p_1'] - df['label'])\n",
        "wrong_df = df.sort_values(by='abs_diff', ascending=False)\n",
        "\n",
        "# Display the top 10 rows\n",
        "print(wrong_df[['filePath', 'p_1', 'label']].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLy1ziuMqNoW",
        "outputId": "f60cac95-96cd-45a9-de24-5ebe14865777"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       filePath  p_1  label\n",
            "2  path/to/img3  0.6      1\n",
            "1  path/to/img2  0.2      0\n",
            "0  path/to/img1  0.9      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load the InceptionV3 model pre-trained on ImageNet\n",
        "model = InceptionV3(weights='imagenet', include_top=True)\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_and_preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(299, 299))  # Resize to match InceptionV3 input size\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array = preprocess_input(img_array)\n",
        "    return img_array\n",
        "\n",
        "# Function to make predictions\n",
        "def predict_image(img_path):\n",
        "    img_array = load_and_preprocess_image(img_path)\n",
        "    print(f\"Predicting for image: {img_path}\")  # Debug print\n",
        "    predictions = model.predict(img_array)\n",
        "    decoded_predictions = decode_predictions(predictions, top=10)[0]\n",
        "    print(f\"Predictions: {decoded_predictions}\")  # Debug print\n",
        "    pred_labels = [f\"{label}: {prob:.4f}\" for (_, label, prob) in decoded_predictions]\n",
        "    return pred_labels\n",
        "\n",
        "# Load image paths and make predictions\n",
        "image_paths = [os.path.join(sample_img_dir, fname) for fname in os.listdir(sample_img_dir) if os.path.isfile(os.path.join(sample_img_dir, fname))]\n",
        "print(f\"Image paths: {image_paths}\")  # Debug print\n",
        "\n",
        "results = []\n",
        "for img_path in image_paths:\n",
        "    preds = predict_image(img_path)\n",
        "    results.append({\n",
        "        'filePath': img_path,\n",
        "        'predicted_labels': ', '.join(preds)\n",
        "    })\n",
        "\n",
        "# Print results to verify\n",
        "print(f\"Results: {results}\")\n",
        "\n",
        "# Create a DataFrame with the results\n",
        "predictions_df = pd.DataFrame(results)\n",
        "\n",
        "# Print column names and first few rows to verify\n",
        "print(predictions_df.columns)\n",
        "print(predictions_df.head())\n",
        "\n",
        "# Display the results\n",
        "print(predictions_df[['filePath', 'predicted_labels']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh25BaezqUVq",
        "outputId": "3817d85c-9c56-4f90-fcb8-1ea35961cd7a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m96112376/96112376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Image paths: ['/content/content/photos/sample/10140303196_b88d3d6cec.jpg', '/content/content/photos/sample/100930342_92e8746431_n.jpg', '/content/content/photos/sample/100080576_f52e8ee070_n.jpg']\n",
            "Predicting for image: /content/content/photos/sample/10140303196_b88d3d6cec.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Predictions: [('n11939491', 'daisy', 0.9532104), ('n02219486', 'ant', 0.0006175274), ('n02206856', 'bee', 0.00051203516), ('n02190166', 'fly', 0.00040093914), ('n02165456', 'ladybug', 0.0003706872), ('n02281406', 'sulphur_butterfly', 0.00030587966), ('n02112018', 'Pomeranian', 0.0002901102), ('n01795545', 'black_grouse', 0.0002566795), ('n02177972', 'weevil', 0.00024875405), ('n07745940', 'strawberry', 0.00023729533)]\n",
            "Predicting for image: /content/content/photos/sample/100930342_92e8746431_n.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
            "Predictions: [('n03930313', 'picket_fence', 0.16161872), ('n11939491', 'daisy', 0.13888375), ('n03991062', 'pot', 0.04581202), ('n02206856', 'bee', 0.038976494), ('n13133613', 'ear', 0.020573094), ('n02280649', 'cabbage_butterfly', 0.018795904), ('n03457902', 'greenhouse', 0.015378466), ('n02219486', 'ant', 0.01377997), ('n12620546', 'hip', 0.012666236), ('n02281406', 'sulphur_butterfly', 0.012452311)]\n",
            "Predicting for image: /content/content/photos/sample/100080576_f52e8ee070_n.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step\n",
            "Predictions: [('n11939491', 'daisy', 0.89181435), ('n02219486', 'ant', 0.0012404532), ('n02206856', 'bee', 0.0008130472), ('n02190166', 'fly', 0.0006038048), ('n02165456', 'ladybug', 0.0006005449), ('n02281406', 'sulphur_butterfly', 0.0005320966), ('n04599235', 'wool', 0.0004665363), ('n02112018', 'Pomeranian', 0.00046253437), ('n07930864', 'cup', 0.00044006202), ('n02177972', 'weevil', 0.0004243414)]\n",
            "Results: [{'filePath': '/content/content/photos/sample/10140303196_b88d3d6cec.jpg', 'predicted_labels': 'daisy: 0.9532, ant: 0.0006, bee: 0.0005, fly: 0.0004, ladybug: 0.0004, sulphur_butterfly: 0.0003, Pomeranian: 0.0003, black_grouse: 0.0003, weevil: 0.0002, strawberry: 0.0002'}, {'filePath': '/content/content/photos/sample/100930342_92e8746431_n.jpg', 'predicted_labels': 'picket_fence: 0.1616, daisy: 0.1389, pot: 0.0458, bee: 0.0390, ear: 0.0206, cabbage_butterfly: 0.0188, greenhouse: 0.0154, ant: 0.0138, hip: 0.0127, sulphur_butterfly: 0.0125'}, {'filePath': '/content/content/photos/sample/100080576_f52e8ee070_n.jpg', 'predicted_labels': 'daisy: 0.8918, ant: 0.0012, bee: 0.0008, fly: 0.0006, ladybug: 0.0006, sulphur_butterfly: 0.0005, wool: 0.0005, Pomeranian: 0.0005, cup: 0.0004, weevil: 0.0004'}]\n",
            "Index(['filePath', 'predicted_labels'], dtype='object')\n",
            "                                            filePath  \\\n",
            "0  /content/content/photos/sample/10140303196_b88...   \n",
            "1  /content/content/photos/sample/100930342_92e87...   \n",
            "2  /content/content/photos/sample/100080576_f52e8...   \n",
            "\n",
            "                                    predicted_labels  \n",
            "0  daisy: 0.9532, ant: 0.0006, bee: 0.0005, fly: ...  \n",
            "1  picket_fence: 0.1616, daisy: 0.1389, pot: 0.04...  \n",
            "2  daisy: 0.8918, ant: 0.0012, bee: 0.0008, fly: ...  \n",
            "                                            filePath  \\\n",
            "0  /content/content/photos/sample/10140303196_b88...   \n",
            "1  /content/content/photos/sample/100930342_92e87...   \n",
            "2  /content/content/photos/sample/100080576_f52e8...   \n",
            "\n",
            "                                    predicted_labels  \n",
            "0  daisy: 0.9532, ant: 0.0006, bee: 0.0005, fly: ...  \n",
            "1  picket_fence: 0.1616, daisy: 0.1389, pot: 0.04...  \n",
            "2  daisy: 0.8918, ant: 0.0012, bee: 0.0008, fly: ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load the InceptionV3 model pre-trained on ImageNet\n",
        "model = InceptionV3(weights='imagenet', include_top=True)\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_and_preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(299, 299))  # Resize to match InceptionV3 input size\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array = preprocess_input(img_array)\n",
        "    return img_array\n",
        "\n",
        "# Function to make predictions and get probabilities for 'daisy'\n",
        "def predict_image(img_path):\n",
        "    img_array = load_and_preprocess_image(img_path)\n",
        "    predictions = model.predict(img_array)\n",
        "    decoded_predictions = decode_predictions(predictions, top=10)[0]\n",
        "    # Get the probability for the 'daisy' class\n",
        "    daisy_prob = next((prob for (_, label, prob) in decoded_predictions if label == 'daisy'), 0)\n",
        "    return daisy_prob\n",
        "\n",
        "# Load image paths\n",
        "sample_img_dir = '/content/content/photos/sample'  # Update with your image directory path\n",
        "image_paths = [os.path.join(sample_img_dir, fname) for fname in os.listdir(sample_img_dir) if os.path.isfile(os.path.join(sample_img_dir, fname))]\n",
        "\n",
        "# Get predictions\n",
        "results = []\n",
        "for img_path in image_paths:\n",
        "    daisy_prob = predict_image(img_path)\n",
        "    results.append({\n",
        "        'filePath': img_path,\n",
        "        'p_daisy': daisy_prob\n",
        "    })\n",
        "\n",
        "# Create a DataFrame with the results\n",
        "predictions_df = pd.DataFrame(results)\n",
        "\n",
        "# Process probabilities: Calculate (1 - p_daisy)\n",
        "predictions_df['p_daisy'] = 1 - predictions_df['p_daisy']\n",
        "\n",
        "# Display the results\n",
        "print(predictions_df[['filePath', 'p_daisy']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNhqOYD_qvEI",
        "outputId": "61e60b03-ffdc-4766-febd-98948a613b78"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
            "                                            filePath   p_daisy\n",
            "0  /content/content/photos/sample/10140303196_b88...  0.046790\n",
            "1  /content/content/photos/sample/100930342_92e87...  0.861116\n",
            "2  /content/content/photos/sample/100080576_f52e8...  0.108186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "import os\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (299, 299)\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_and_preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=IMAGE_SIZE)  # Resize to match model input size\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array = preprocess_input(img_array)\n",
        "    return img_array\n",
        "\n",
        "# Function to transform images using TensorFlow\n",
        "def transform_image(img_path):\n",
        "    img_array = load_and_preprocess_image(img_path)\n",
        "\n",
        "    # Define the model\n",
        "    model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "    # Create a TensorFlow function to run the model\n",
        "    model_function = tf.function(lambda x: model(x))\n",
        "\n",
        "    # Run the model on the image\n",
        "    transformed_images = model_function(img_array)\n",
        "\n",
        "    return transformed_images\n",
        "\n",
        "# Load image paths\n",
        "sample_img_dir = '/content/content/photos/sample'  # Update with your image directory path\n",
        "image_paths = [os.path.join(sample_img_dir, fname) for fname in os.listdir(sample_img_dir) if os.path.isfile(os.path.join(sample_img_dir, fname))]\n",
        "\n",
        "# Transform images\n",
        "transformed_images = []\n",
        "for img_path in image_paths:\n",
        "    transformed_img = transform_image(img_path)\n",
        "    transformed_images.append({\n",
        "        'filePath': img_path,\n",
        "        'transformed_image': transformed_img.numpy().squeeze()  # Remove batch dimension\n",
        "    })\n",
        "\n",
        "# Create a DataFrame with the results\n",
        "transformed_df = pd.DataFrame(transformed_images)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(transformed_df[['filePath']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRzezdodrB1B",
        "outputId": "763f1ee2-b310-4ad9-8c7a-247b5bd5242f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            filePath\n",
            "0  /content/content/photos/sample/10140303196_b88...\n",
            "1  /content/content/photos/sample/100930342_92e87...\n",
            "2  /content/content/photos/sample/100080576_f52e8...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def remove_dir(dir_path):\n",
        "    \"\"\"Remove a directory and its contents.\"\"\"\n",
        "    if os.path.exists(dir_path):\n",
        "        shutil.rmtree(dir_path)\n",
        "        print(f\"Removed directory: {dir_path}\")\n",
        "    else:\n",
        "        print(f\"Directory does not exist: {dir_path}\")\n",
        "\n",
        "# Define your directories\n",
        "img_dir = '/content/content/photos'  # Update with your image directory path\n",
        "dbfs_model_path = '/content/content/model'  # Update with your model path\n",
        "\n",
        "# Remove directories\n",
        "remove_dir(img_dir)\n",
        "remove_dir(dbfs_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCepSNBZrHEs",
        "outputId": "4b35cebc-436d-45c3-d820-3abb862bfb1a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed directory: /content/content/photos\n",
            "Directory does not exist: /content/content/model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pju1BqgptW20"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}